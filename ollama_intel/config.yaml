name: "Ollama (Intel AI Core)"
version: "0.5.7-7"
slug: "ollama_intel"
description: "Ollama with Intel Arc GPU support for Arrow Lake. Optimized for Intel hardware."
url: "https://github.com/matthijsberg/HA-AI-Addons"
startup: application
boot: auto
arch:
  - amd64
privileged:
  - SYS_ADMIN
  - SYS_RAWIO
  - SYS_PTRACE
full_access: true
devices:
  - /dev/dri:/dev/dri
  - /dev/video0:/dev/video0
ports:
  11434/tcp: 11434
ports_description:
  11434/tcp: "The Ollama API Port, not used for End-User Access"
ingress: true
ingress_port: 11434
ingress_stream: true
video: true
map:
  - config:rw
  - share:rw
options:
  models: 
    - "llama3.2:3b"
  keep_alive: "5m"
watchdog: tcp://[HOST]:11434
schema:
  models:
    - str
  keep_alive: str